\documentclass{article}

\usepackage[final]{nips_2017}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{courier}
\usepackage{multirow}

\lstset{basicstyle=\ttfamily\footnotesize,breaklines=true}
\title{CSE 253 Programming Assignment 3 -- Convolution Neural Networks}

\author{
  Fanjin Zeng \\
  Computer Science and Engineering\\
  University of Califorina, San Diego\\
  \texttt{f1zeng@ucsd.edu} \\
   \And
   Xinyue Ou \\
   Computer Science and Engineering\\
   University of Califorina, San Diego \\
   \texttt{x1ou@ucsd.edu} \\
   \And
   He Qin \\
   Computer Science and Engineering\\
   University of Califorina, San Diego \\
   \texttt{h9qin@ucsd.edu} \\
   \And
   Yuhan Chen \\
   Computer Science and Engineering\\
   University of Califorina, San Diego \\
   \texttt{yuc143@ucsd.edu} \\
}

\begin{document}

\maketitle
\begin{abstract}
In this assignment, we first implemented convolutional neural networks for image classification, then explored transfer learning using the PyTorch framework. In our first experiment, our best network model reached 82.8\% prediction accuracy over test set. 

\end{abstract}

\section{Deep Convolution Network for Image Classification}
\subsection{Model Architecture}
Here, we present the 3 best networks as explained below. Specifically, we increase the depth of each network, and also try different layers like Conv, BatchNorm, ReLU, MaxPool, Dropout and FC etc.

Model 1 was inspired by the paper [2]. We set the depth to 13 conv layer, 1 fully connected, and one softmax layer. For the convolutional layers, the layer in the front uses 3x3 kernel to make full use of the locality information, while in the rear only 1x1 kernel is used to reduce the number of parameters.

For Model 2, we employ only 5 convolutional layer to build the network. It uses different size of the kernel for the convolution layer, ranging from 1x1 to 5x5. Dropout layer is also used in some convolution layer. 

Model 3 is the most simple network we build. It has only 4 convolutional layers, with BatchNorm, Maxpooling and ReLU.



\begin{table}[htbp]
\begin{minipage}[t]{0.48\textwidth}
  \centering
  \caption{Architecture of Model 1}
    \begin{tabular}{c|l}
    \multirow{3}[0]{*}{conv1} & Conv 3x3 @3x64 \\
          & BatchNorm2d \\
          & ReLU  \\
\hline \\ [-1.5ex]
    \multirow{3}[0]{*}{conv2} & Conv 3x3 @64x128 \\
          & BatchNorm2d \\
          & ReLU  \\
\hline \\ [-1.5ex]
    \multirow{3}[0]{*}{conv3} & Conv 3x3 @128x128 \\
          & BatchNorm2d \\
          & ReLU  \\
\hline \\ [-1.5ex]
    \multirow{4}[0]{*}{conv4} & Conv 3x3 @128x128 \\
          & BatchNorm2d \\
          & ReLU  \\
          & MaxPool 2x2 \\\hline \\ [-1.5ex]
    \multirow{3}[0]{*}{conv5} & Conv 3x3 @128x128 \\
          & BatchNorm2d \\
          & ReLU  \\\hline \\ [-1.5ex]
    \multirow{3}[0]{*}{conv6} & Conv 3x3 @128x128 \\
          & BatchNorm2d \\
          & ReLU  \\\hline \\ [-1.5ex]
    \multirow{4}[0]{*}{conv7} & Conv 3x3 @128x128 \\
          & BatchNorm2d \\
          & ReLU  \\
          & MaxPool 2x2 \\\hline \\ [-1.5ex]
    \multirow{3}[0]{*}{conv8} & Conv 3x3 @128x128 \\
          & BatchNorm2d \\
          & ReLU  \\\hline \\ [-1.5ex]
    \multirow{4}[0]{*}{conv9} & Conv 3x3 @128x128 \\
          & BatchNorm2d \\
          & ReLU  \\
          & MaxPool 2x2 \\\hline \\ [-1.5ex]
    \multirow{3}[0]{*}{conv10} & Conv 3x3 @128x128 \\
          & BatchNorm2d \\
          & ReLU  \\\hline \\ [-1.5ex]
    \multirow{3}[0]{*}{conv11} & Conv 1x1 @128x128 \\
          & BatchNorm2d \\
          & ReLU  \\\hline \\ [-1.5ex]
    \multirow{4}[0]{*}{conv12} & Conv 1x1 @128x128 \\
          & BatchNorm2d \\
          & ReLU  \\
          & MaxPool 2x2 \\\hline \\ [-1.5ex]
    \multirow{4}[0]{*}{conv13} & Conv 3x3 @128x128 \\
          & BatchNorm2d \\
          & ReLU  \\
          & MaxPool 2x2 \\\hline \\ [-1.5ex]
    fc    & Linear 512x10 \\\hline \\ [-1.5ex]
    sm    & Softmax \\
    \end{tabular}%
  \label{tab:1}%
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
  \centering
  \caption{Architecture of Model 2}
    \begin{tabular}{c|l}
    \multirow{4}[0]{*}{conv1} & Conv 5x5 @3x128 \\
          & BatchNorm2d \\
          & ReLU  \\
          & MaxPool 2x2 stride2x2 \\
          \hline \\ [-1.5ex]
    \multirow{4}[0]{*}{conv2} & Conv 5x5 @128x256 \\
          & BatchNorm2d \\
          & ReLU  \\
          & MaxPool 2x2 stride2x2 \\\hline \\ [-1.5ex]
    \multirow{3}[0]{*}{conv3} & Conv 4x4 @256x512 \\
          & BatchNorm2d \\
          & ReLU  \\\hline \\ [-1.5ex]
    \multirow{4}[0]{*}{conv4} & Conv 2x2 @512x1024 \\
          & BatchNorm2d \\
          & ReLU  \\
          & Dropout p=0.5 \\\hline \\ [-1.5ex]
    \multirow{2}[0]{*}{conv5} & Conv 1x1 @1024x10 \\
          & BatchNorm2d \\\hline \\ [-1.5ex]
    fc    & Linear 90x10 \\\hline \\ [-1.5ex]
    sm    & Softmax \\
    \end{tabular}%
  \label{tab:2}%

 \vspace{10em}
       \centering
        \caption{Architecture of Model 3}
          \begin{tabular}{cl}
          \multirow{3}[0]{*}{conv1} & Conv 5x5 @3x16 \\
                & BatchNorm2d \\
                & ReLU  \\ \hline \\ [-1.5ex]
          \multirow{3}[0]{*}{conv2} & Conv 5x5 @16x64 \\
                & BatchNorm2d \\
                & ReLU  \\ \hline \\ [-1.5ex]
          \multirow{2}[0]{*}{fc1} & Linear 1600x120 \\
                & ReLU  \\ \hline \\ [-1.5ex]
          \multirow{2}[0]{*}{fc2} & Linear 120x84 \\
                & ReLU  \\\hline \\ [-1.5ex]
          fc3   & Linear 120x10 \\\hline \\ [-1.5ex]
          sm    & Softmax \\
          \end{tabular}%
        \label{tab:3}%
      
  \end{minipage}
  
\end{table}%

\newpage

\subsection{Optimization Technique}
\subsubsection{Batch Normalization}
When we fit a normalized input to the network, the gradient descent algorithm will undo the normalization in order to reduce the loss. This however will result in the shift of the underlying distribution of the data. As the input increase, some activation will reach the saturation regime except for those with small absolute value. Therefore, in order to get rid of the vanish of gradients, we use normalization to eliminate the dependency of the scale of parameters. It can then accelerate the process of training. [3]
\subsubsection{Xavier Intialization}
Xavier weight initialization is to let the variance of the input and the variance of the output from the forward phase remains the same.  To achieve this, Xavier initialization initializes the weights as a normal distribution with 0 mean and a variance to be \begin{align*}
Var(W) = \frac{1}{n_{in}}
\end{align*}

This proper initialization can help accelerate the training process

\subsubsection{Adam Optimizer}
We use adam optimizer for updating parameters, this usually helps to get faster convergence. It benefits from both AdaGrad and RMSProp
\subsection{Results and Analysis}

For the training, each model is trained for 30 epochs. We use early stop criterion based on the validation loss, if the validation loss keeps going up for 3 epochs, which means the model is overfitting, we stops the training at once. 

All the three models go through the 30 epochs without early stop. As the results show, the first model has the highest testing accuracy despite the training accuracy not as high as model 2, which shows that model 1 has a better generality compared to model 2. This may due the fact that deeper networks can learn more sophisticated inner representation. From the rising tendency of the testing and validation loss of Model 3, we can tell that this model is overfitting on the training data. This along with the low training accuracy show that shallow networks have defects in both generality and representing the data. 

\begin{table}[htbp]
  \centering
  \caption{Results}
    \begin{tabular}{l|lll}
          & Model 1 & Model 2 & Model 3 \\\hline \\ [-1.5ex]
    Train Accuracy & 92.1\%    & 96.1\% & 83.7\%     \\
    Validate Accuracy &   82.7\%  & 79.1\% & 63.4\%     \\
    Test Accuracy & 82.8\%    & 78.81\%  & 62.8\%    \\\hline \\ [-1.5ex]
    Train Loss & 0.0120    & 0.0117 & 0.0040     \\
    Validate Loss   & 0.0130    & 0.0133 & 0.0099   \\
    Test Loss & 0.0130    & 0.0131 & 0.0100     \\
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}%



\begin{figure}[h]
\begin{minipage}{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{pics/1_loss.png}
\caption{Model 1 Loss}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{pics/1_acc.png}
\caption{Model 1 Accuracy}
\end{minipage}

\begin{minipage}{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{pics/2_loss.png}
\caption{Model 2 Loss}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{pics/2_acc.png}
\caption{Model 2 Accuracy}
\end{minipage}

\begin{minipage}{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{pics/t_loss.png}
\caption{Model 3 Loss}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
\centering
\includegraphics[width=\textwidth]{pics/t_acc.png}
\caption{Model 3 Accuracy}
\end{minipage}
\end{figure}
\subsection{Conclusion}
\begin{enumerate}
\item Deep network structure has better generality from train to test set, while shallw network structure tends to overfit, which usually has good accuracy on train set, but has poor accuracy on test set.
\item Depth of the network matters.
\item Techniques of batch-normalization, Xavier and Adam improves.

\end{enumerate}



\newpage
\section{Transfer Learning}
For this part, we used transfer learning with a VGG16 (with batch normalization) network with weights pretrained on ImageNet data (as vgg16\_bn in pytorch). The dataset used was Caltech256, which has 256 classes. We froze the weights of all layers except for the last fully connected layer with softmax. The last layer, originally with 1000 output units, was changed to 256 units and only this layer was trained. We used 32 images per class for training and 8 images per class for testing.\\
To further explore the features learned by VGG16 network, we used an example image of a dog and passed it through the trained network. The activation maps of the first and last convolutional layers were visualized and analyzed. The filters from the first convolutional layer were also plotted.\\

\subsection{Results}
The plots of accuracy and loss against number of epochs are shown below. After 2 epochs, the loss of training set continues to decrease while the test set maintains a consistent value with small oscillations. The train and test plots diverge after then, indicating overfitting on the training set. Eventually the final accuracy of train set is 86\% and accuracy of test set is 75\%.\\
This is a good result considering only 32 training images were used per class. The good performance indicates that the weights trained from ImageNet are helpful in classifying a new dataset that has similar objects as ImageNet.\\
\begin{figure}[h!]
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{part2_pics/loss_epochs.png}
		\caption{Transfer Learning Model Loss}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{part2_pics/acc_epochs.png}
		\caption{Transfer Learning Model Accuracy}
	\end{minipage}
\end{figure}
\subsection{Visualization}
A dog image is passed through the trained network. The selected activation maps of the first and last convolutional layers (10 each) are shown below. The activation maps of the first convolutional layer look very similar to the original image, but with different regions of activations (the bright pixels). This is because each activation map corresponds to a different 2-D filter of basic structures (edges, lines and so on). On the other hand, the activation maps of the last convolutional layer do not look like a dog at all. This result is exactly as expected. The filters of the last layer should contain high level structures of objects (head, body, and so on), and the activation maps simply indicate whether these structures are found in the image.\\

\begin{figure}[h!]
		\centering
		\includegraphics[width=0.47\textwidth]{part2_pics/original_img.png}
		\caption{Original image}
\end{figure}

\begin{figure}[h!]
		\centering
		\includegraphics[width=0.8\textwidth]{part2_pics/conv_activations_0.png}
		\caption{Activation maps of first conv layer}
\end{figure}
\begin{figure}[h!]
		\centering
		\includegraphics[width=0.8\textwidth]{part2_pics/conv_activations_1.png}
		\caption{Activation maps of the last conv layer (up)}
\end{figure}
Some filters of the first convolutional layer are shown below. As expected, they represent lines and edges. \\
\begin{figure}[h!]
		\centering
		\includegraphics[width=0.8\textwidth]{part2_pics/conv1_filters.png}
		\caption{Filters of first conv layer}
\end{figure}

\subsection{Feature Extraction}
We use the third and forth intermediate Convolutional blocks as input, and sequentially pass it through a fully connected layer(1024 outputs), a relu layer, a fully connected layer(256 outputs) and a softmax layer. The rest parameters are fixed during the training. \\
For the third intermediate block input, we use adam optimizer with learning rate 0.00001. After 10 epochs of training, we get 99.41\% accuracy on train set and 27.78\% accuracy on test set.\\

\begin{figure}[h!]
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{pics/fe_block3_loss_10epochs.png}
		\caption{Block 3 Feature Extraction Training Loss}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{pics/fe_block3_acc_10epochs.png}
		\caption{Block 3 Feature Extraction Training Accuracy}
	\end{minipage}
\end{figure}

For the fourth intermediate block input, we use adam optimizer with learning rate 0.0001. After 5 epochs of training, we get 99.66\% accuracy on train set and 44.72\% accuracy on test set.

\begin{figure}[h!]
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{pics/fe_block4_loss.png}
		\caption{Block 4 Feature Extraction Training Loss}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{pics/fe_block4_acc.png}
		\caption{Block 4 Feature Extraction Training Accuracy}
	\end{minipage}
\end{figure}

The result of our experiment indicates the network have achieved relatively well classification accuracy in fourth convolutional block, and it significantly out performs the third convolutional block. Deeper networks indeed did a much better job than shallow ones.

\newpage

\section{Contributions}
Fanjin Zeng and Yuhan Chen are in charge of implementation of transfer learning. Fanjin implemented parts of the new VGG model and he wrote the code for feature extraction. Yuhan implemented parts of the new VGG model and he wrote the code for filter visualization.


\section{References}
[1] Bishop, C. M., {\it Neural networks for pattern recognition}, Oxford: Oxford University Press, 2013. \\

[2] Hasanpour, Seyyed Hossein, et al. "Lets keep it simple, Using simple architectures to outperform deeper and more complex architectures." arXiv preprint arXiv:1608.06037 (2016). \\

[3]Ioffe, Sergey, and Christian Szegedy. "Batch normalization: Accelerating deep network training by reducing internal covariate shift." International conference on machine learning. 2015.\\

[4] PyTorch Tutorial, Training a classifier
 
 \url{http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html}\\
 
[5] Transfer Learning tutorial

\url{http://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html}

\end{document}