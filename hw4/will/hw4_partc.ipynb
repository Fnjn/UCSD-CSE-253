{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from rnn_will import RNN, PrepareData\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_dim = 7\n",
    "\"\"\"\n",
    "part d change dropout\n",
    "\"\"\"\n",
    "drop_ratio = 0.2\n",
    "hidden_dim = 50\n",
    "num_layers = 1\n",
    "seq_size = 25\n",
    "all_letters = string.printable\n",
    "n_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15688 3921\n"
     ]
    }
   ],
   "source": [
    "dataset = PrepareData('../input.txt', seq_size, val_ratio=0.2)\n",
    "#dataset = PrepareData('sample-music2.txt', seq_size)\n",
    "train_data, val_data = dataset.dataset()\n",
    "print(train_data.__len__(), val_data.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputTensor(line):\n",
    "    if len(line) == 1:\n",
    "        tensor = torch.zeros(1, n_letters)\n",
    "        tensor[0, all_letters.find(line[0])] = 1\n",
    "    else:\n",
    "        tensor = torch.zeros(len(line)-1, n_letters)\n",
    "        for idx, letter in enumerate(line[:-1]):\n",
    "            tensor[idx, all_letters.find(letter)] = 1\n",
    "    return Variable(tensor.cuda())\n",
    "        \n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(letter) for letter in line[1:]]\n",
    "    return Variable(torch.LongTensor(letter_indexes).cuda())\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    \n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(n_letters, hidden_dim, num_layers=num_layers, output_size=n_letters, drop_ratio=drop_ratio)\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 0\n",
      "0m:48s -- [0, 2000], loss: 3.088835\n",
      "1m:38s -- [0, 4000], loss: 2.552830\n",
      "2m:26s -- [0, 6000], loss: 2.150777\n",
      "3m:15s -- [0, 8000], loss: 2.046539\n",
      "4m:4s -- [0, 10000], loss: 1.836284\n",
      "4m:55s -- [0, 12000], loss: 1.801843\n",
      "5m:45s -- [0, 14000], loss: 1.819676\n",
      "#, loss: Variable containing:\n",
      " 2.1207\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "#0, loss: 2.5685789990583165\n",
      "#1, loss: 3.3667527034829328\n",
      "Epoch # 1\n",
      "7m:46s -- [1, 2000], loss: 2.195151\n",
      "8m:34s -- [1, 4000], loss: 2.086817\n",
      "9m:21s -- [1, 6000], loss: 1.783132\n",
      "10m:8s -- [1, 8000], loss: 1.764218\n",
      "10m:57s -- [1, 10000], loss: 1.632750\n",
      "11m:52s -- [1, 12000], loss: 1.632263\n",
      "12m:43s -- [1, 14000], loss: 1.664883\n",
      "#, loss: Variable containing:\n",
      " 1.7864\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "#0, loss: 2.4709117785105668\n",
      "#1, loss: 3.2605709320609284\n",
      "Epoch # 2\n",
      "14m:54s -- [2, 2000], loss: 2.004482\n",
      "15m:45s -- [2, 4000], loss: 1.956818\n",
      "16m:34s -- [2, 6000], loss: 1.662453\n",
      "17m:24s -- [2, 8000], loss: 1.669388\n",
      "18m:16s -- [2, 10000], loss: 1.558773\n",
      "19m:8s -- [2, 12000], loss: 1.558923\n",
      "19m:58s -- [2, 14000], loss: 1.593656\n",
      "#, loss: Variable containing:\n",
      " 1.6852\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "#0, loss: 2.4134811139363967\n",
      "#1, loss: 3.1987155363347513\n",
      "Epoch # 3\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "all_losses = []\n",
    "\n",
    "print_every = 2000\n",
    "init_hidden_every = 35\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "loss_history = np.zeros((n_epochs, 2))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print('Epoch # {}'.format(epoch))\n",
    "    train_cnt = 0\n",
    "    total_loss = 0.\n",
    "    running_loss = 0. #for checking purpose\n",
    "    \n",
    "    model.hidden = model.init_hidden()\n",
    "    \n",
    "    #dataset.shuffle_data()\n",
    "    #train_data, val_data = dataset.dataset()\n",
    "#     model.train(True)\n",
    "    for sentence in train_data:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        loss = 0.\n",
    "        inputs = inputTensor(sentence)\n",
    "        targets = targetTensor(sentence)\n",
    "        \n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds, targets)\n",
    "            \n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        train_cnt += 1\n",
    "        \n",
    "        if train_cnt % init_hidden_every == 0:\n",
    "            model.hidden = model.init_hidden()\n",
    "        \n",
    "        if train_cnt % print_every == 0:\n",
    "            total_loss /= print_every\n",
    "            all_losses.append(total_loss)\n",
    "            uptime = time.time() - start_time\n",
    "            print('%dm:%ds -- [%d, %d], loss: %f' % (uptime/60, uptime%60, epoch, train_cnt, total_loss.data[0]))\n",
    "            total_loss = 0\n",
    "            \n",
    "        running_loss += loss\n",
    "    dataset_size = train_data.__len__()\n",
    "    epoch_loss = running_loss / float(dataset_size)\n",
    "    print('#, loss: {}'.format(epoch_loss))\n",
    "            \n",
    "#     model.train(False)\n",
    "    for idx, dataloader in enumerate([train_data, val_data]):\n",
    "        # compute loss\n",
    "        running_loss = 0.\n",
    "        for sentence in dataloader:\n",
    "            loss = 0.\n",
    "            inputs = inputTensor(sentence)\n",
    "            targets = targetTensor(sentence)\n",
    "            preds = model(inputs)\n",
    "            loss = criterion(preds, targets)\n",
    "            running_loss += loss.data[0]\n",
    "            #\n",
    "        # save loss\n",
    "        dataset_size = dataloader.__len__()\n",
    "        epoch_loss = running_loss / float(dataset_size)\n",
    "        print('#{}, loss: {}'.format(idx, epoch_loss))\n",
    "        # print(type(epoch_loss), type(epoch_acc))\n",
    "\n",
    "        loss_history[epoch, idx] = epoch_loss\n",
    "            \n",
    "            \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.67063644  3.3763115 ]\n",
      " [ 2.49499452  3.20083674]\n",
      " [ 2.42300944  3.12763692]\n",
      " [ 2.40567135  3.11331172]\n",
      " [ 2.40854176  3.1275137 ]\n",
      " [ 2.40196493  3.12615618]\n",
      " [ 2.30638868  2.99898691]\n",
      " [ 2.30016639  2.97397985]\n",
      " [ 2.29872055  2.96516224]\n",
      " [ 2.29920088  2.96051653]\n",
      " [ 2.30110986  2.95799984]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.29872055  2.96516224]]\n"
     ]
    }
   ],
   "source": [
    "# print(loss_history[8])\n",
    "\n",
    "temp = np.concatenate((loss_history, np.array([loss_history[8]])), axis=0)\n",
    "print(temp)\n",
    "# print(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'partc_drop_{}_loss_history.npy'.format(drop_ratio)\n",
    "np.save(fname, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb4789fcda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = np.load(fname)\n",
    "plt.plot(range(16), temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test(start_with, max_length):\n",
    "    model.hidden = model.init_hidden()\n",
    "    seq = str(start_with)\n",
    "    idx = []\n",
    "    \n",
    "    if len(start_with) > 1:\n",
    "        inputs = inputTensor(seq)\n",
    "        output = model(inputs)\n",
    "    \n",
    "    inputs = inputTensor(seq[-1])\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        output = model(inputs)\n",
    "        #pr = F.softmax(output.data, 1)  //pytorch 3.0+\n",
    "        pr = F.softmax(output.data)\n",
    "        pr = pr.cpu().data.numpy().squeeze()\n",
    "        pred = np.random.choice(n_letters, 1, p=pr)\n",
    "        \n",
    "        seq += all_letters[pred[0]]\n",
    "        idx.append(pred[0])\n",
    "        inputs = inputTensor(seq[-1])\n",
    "    return seq, idx\n",
    "\n",
    "def teacher_forcing_test(sentence):\n",
    "    inputs = inputTensor(sentence)\n",
    "    output = model(inputs)\n",
    "    _, preds = torch.max(output.data, 1)\n",
    "    seq = [all_letters[pred] for pred in preds ]\n",
    "    return ''.join(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = val_data[0]\n",
    "start_char = test_seq[:10]\n",
    "\n",
    "seq, idx = test(start_char, 900)\n",
    "print('Generated sequence: %s' % (seq))\n",
    "#print('Sequence index: ', idx)\n",
    "#print('Test sequence: %s' % test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = val_data[99]\n",
    "start_char = test_seq[:10]\n",
    "\n",
    "seq, idx = test(start_char, 900)\n",
    "print('Generated sequence: %s' % (seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = val_data[0]\n",
    "seq = teacher_forcing_test(test_seq)\n",
    "print('Generated sequence: %s' % (seq))\n",
    "print('Test sequence: %s' % test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model, 'full-model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
