{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from rnn import RNN, PrepareData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_dim = 7\n",
    "hidden_dim = 30\n",
    "num_layers = 2\n",
    "seq_size = 25\n",
    "all_letters = string.printable\n",
    "n_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset = PrepareData('input.txt', seq_size, val_ratio=0.2)\n",
    "dataset = PrepareData('sample-music2.txt', seq_size)\n",
    "train_data, val_data = dataset.dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputTensor(line):\n",
    "    if len(line) == 1:\n",
    "        tensor = torch.zeros(1, n_letters)\n",
    "        tensor[0, all_letters.find(line[0])] = 1\n",
    "    else:\n",
    "        tensor = torch.zeros(len(line)-1, n_letters)\n",
    "        for idx, letter in enumerate(line[:-1]):\n",
    "            tensor[idx, all_letters.find(letter)] = 1\n",
    "    return Variable(tensor.cuda())\n",
    "        \n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(letter) for letter in line[1:]]\n",
    "    return Variable(torch.LongTensor(letter_indexes).cuda())\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    \n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(n_letters, hidden_dim, num_layers=num_layers, output_size=n_letters)\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m:11.707715272903442 -- [0, 500], loss: 1.967980\n",
      "0m:22.397526264190674 -- [0, 1000], loss: 1.957015\n",
      "0m:40.806588888168335 -- [1, 500], loss: 1.957506\n",
      "0m:51.580753803253174 -- [1, 1000], loss: 1.913785\n",
      "1m:9.764806747436523 -- [2, 500], loss: 1.908384\n",
      "1m:20.579535484313965 -- [2, 1000], loss: 1.846005\n",
      "1m:39.05263662338257 -- [3, 500], loss: 1.922634\n",
      "1m:49.94528126716614 -- [3, 1000], loss: 1.826035\n",
      "2m:8.250165700912476 -- [4, 500], loss: 1.854512\n",
      "2m:19.01862144470215 -- [4, 1000], loss: 1.773407\n",
      "2m:37.65753698348999 -- [5, 500], loss: 1.817026\n",
      "2m:48.24101638793945 -- [5, 1000], loss: 1.749392\n",
      "3m:6.459793567657471 -- [6, 500], loss: 1.795434\n",
      "3m:17.06702995300293 -- [6, 1000], loss: 1.719495\n",
      "3m:35.34467554092407 -- [7, 500], loss: 1.779078\n",
      "3m:49.22354006767273 -- [7, 1000], loss: 1.691813\n",
      "4m:12.409470319747925 -- [8, 500], loss: 1.746116\n",
      "4m:24.02322292327881 -- [8, 1000], loss: 1.668914\n",
      "4m:41.13911437988281 -- [9, 500], loss: 1.731472\n",
      "4m:50.33426809310913 -- [9, 1000], loss: 1.649536\n",
      "5m:6.55338978767395 -- [10, 500], loss: 1.707514\n",
      "5m:17.051981449127197 -- [10, 1000], loss: 1.624012\n",
      "5m:37.67594647407532 -- [11, 500], loss: 1.689296\n",
      "5m:49.66954016685486 -- [11, 1000], loss: 1.605433\n",
      "6m:7.665161609649658 -- [12, 500], loss: 1.669116\n",
      "6m:16.471293210983276 -- [12, 1000], loss: 1.596846\n",
      "6m:34.97572040557861 -- [13, 500], loss: 1.654168\n",
      "6m:43.81696820259094 -- [13, 1000], loss: 1.574089\n",
      "6m:58.93555474281311 -- [14, 500], loss: 1.642193\n",
      "7m:8.025715351104736 -- [14, 1000], loss: 1.563397\n",
      "7m:23.13023090362549 -- [15, 500], loss: 1.619921\n",
      "7m:31.95619535446167 -- [15, 1000], loss: 1.550238\n",
      "7m:47.035401582717896 -- [16, 500], loss: 1.608749\n",
      "7m:55.96445107460022 -- [16, 1000], loss: 1.535235\n",
      "8m:13.851298570632935 -- [17, 500], loss: 1.597854\n",
      "8m:23.22939157485962 -- [17, 1000], loss: 1.520899\n",
      "8m:38.33574342727661 -- [18, 500], loss: 1.579201\n",
      "8m:47.159032106399536 -- [18, 1000], loss: 1.511641\n",
      "9m:2.2601077556610107 -- [19, 500], loss: 1.567402\n",
      "9m:11.27365756034851 -- [19, 1000], loss: 1.501952\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "all_losses = []\n",
    "\n",
    "print_every = 500\n",
    "init_hidden_every = 20\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_cnt = 0\n",
    "    total_loss = 0.\n",
    "    \n",
    "    model.hidden = model.init_hidden()\n",
    "    \n",
    "    #dataset.shuffle_data()\n",
    "    #train_data, val_data = dataset.dataset()\n",
    "    \n",
    "    for sentence in train_data:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        loss = 0.\n",
    "        inputs = inputTensor(sentence)\n",
    "        targets = targetTensor(sentence)\n",
    "        \n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds, targets)\n",
    "            \n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        train_cnt += 1\n",
    "        \n",
    "        if train_cnt % init_hidden_every == 0:\n",
    "            model.hidden = model.init_hidden()\n",
    "        \n",
    "        if train_cnt % print_every == 0:\n",
    "            total_loss /= print_every\n",
    "            all_losses.append(total_loss)\n",
    "            uptime = time.time() - start_time\n",
    "            print('%dm:%s -- [%d, %d], loss: %f' % (uptime/60, uptime%60, epoch, train_cnt, total_loss))\n",
    "            total_loss = 0\n",
    "#scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test(start_with, max_length):\n",
    "    model.hidden = model.init_hidden()\n",
    "    seq = str(start_with)\n",
    "    idx = []\n",
    "    inputs = inputTensor(seq[-1])\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        output = model(inputs)\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        \n",
    "        seq += all_letters[pred[0]]\n",
    "        idx.append(pred[0])\n",
    "        inputs = inputTensor(letter)\n",
    "    return seq, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence: M GABAAAAFFAAFAAFFAAFFAFFA\n",
      "Sequence index:  [94, 42, 36, 37, 36, 36, 36, 36, 41, 41, 36, 36, 41, 36, 36, 41, 41, 36, 36, 41, 41, 36, 41, 41, 36]\n",
      "Test sequence: ree.fr\n",
      "M: 4/4\n",
      "L: 1/8\n",
      "Q:1/\n"
     ]
    }
   ],
   "source": [
    "test_seq = train_data[5]\n",
    "\n",
    "seq, idx = test(test_seq[7],25)\n",
    "print('Generated sequence: %s' % (seq))\n",
    "print('Sequence index: ', idx)\n",
    "print('Test sequence: %s' % test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(model, 'sample-model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
