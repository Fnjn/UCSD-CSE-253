{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from rnn import RNN, PrepareData\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_dim = 7\n",
    "hidden_dim = 30\n",
    "num_layers = 2\n",
    "seq_size = 25\n",
    "all_letters = string.printable\n",
    "n_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = PrepareData('input.txt', seq_size, val_ratio=0.2)\n",
    "#dataset = PrepareData('sample-music2.txt', seq_size)\n",
    "train_data, val_data = dataset.dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputTensor(line):\n",
    "    if len(line) == 1:\n",
    "        tensor = torch.zeros(1, n_letters)\n",
    "        tensor[0, all_letters.find(line[0])] = 1\n",
    "    else:\n",
    "        tensor = torch.zeros(len(line)-1, n_letters)\n",
    "        for idx, letter in enumerate(line[:-1]):\n",
    "            tensor[idx, all_letters.find(letter)] = 1\n",
    "    return Variable(tensor.cuda())\n",
    "        \n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(letter) for letter in line[1:]]\n",
    "    return Variable(torch.LongTensor(letter_indexes).cuda())\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    \n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RNN(n_letters, hidden_dim, num_layers=num_layers, output_size=n_letters)\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m:33s -- [0, 2000], loss: 3.439631\n",
      "3m:1s -- [0, 4000], loss: 3.057366\n",
      "4m:27s -- [0, 6000], loss: 2.594595\n",
      "5m:54s -- [0, 8000], loss: 2.458553\n",
      "7m:19s -- [0, 10000], loss: 2.165513\n",
      "8m:46s -- [0, 12000], loss: 2.056389\n",
      "10m:12s -- [0, 14000], loss: 2.067374\n",
      "12m:49s -- [1, 2000], loss: 2.499923\n",
      "14m:15s -- [1, 4000], loss: 2.358352\n",
      "15m:41s -- [1, 6000], loss: 2.000396\n",
      "17m:7s -- [1, 8000], loss: 1.973872\n",
      "18m:34s -- [1, 10000], loss: 1.811090\n",
      "20m:2s -- [1, 12000], loss: 1.804291\n",
      "21m:26s -- [1, 14000], loss: 1.866099\n",
      "24m:2s -- [2, 2000], loss: 2.226062\n",
      "25m:26s -- [2, 4000], loss: 2.173111\n",
      "26m:52s -- [2, 6000], loss: 1.853589\n",
      "28m:19s -- [2, 8000], loss: 1.854437\n",
      "29m:44s -- [2, 10000], loss: 1.712330\n",
      "31m:6s -- [2, 12000], loss: 1.710376\n",
      "32m:30s -- [2, 14000], loss: 1.772854\n",
      "35m:1s -- [3, 2000], loss: 2.102859\n",
      "36m:24s -- [3, 4000], loss: 2.078819\n",
      "37m:48s -- [3, 6000], loss: 1.752376\n",
      "39m:14s -- [3, 8000], loss: 1.787349\n",
      "40m:40s -- [3, 10000], loss: 1.651207\n",
      "42m:8s -- [3, 12000], loss: 1.661962\n",
      "43m:33s -- [3, 14000], loss: 1.720524\n",
      "46m:15s -- [4, 2000], loss: 2.016000\n",
      "47m:46s -- [4, 4000], loss: 2.011120\n",
      "49m:11s -- [4, 6000], loss: 1.699677\n",
      "50m:41s -- [4, 8000], loss: 1.743183\n",
      "52m:8s -- [4, 10000], loss: 1.615043\n",
      "53m:33s -- [4, 12000], loss: 1.626858\n",
      "54m:58s -- [4, 14000], loss: 1.686695\n",
      "57m:31s -- [5, 2000], loss: 1.961718\n",
      "58m:56s -- [5, 4000], loss: 1.964218\n",
      "60m:22s -- [5, 6000], loss: 1.669548\n",
      "61m:49s -- [5, 8000], loss: 1.716316\n",
      "63m:17s -- [5, 10000], loss: 1.595520\n",
      "64m:43s -- [5, 12000], loss: 1.604555\n",
      "66m:6s -- [5, 14000], loss: 1.656959\n",
      "68m:33s -- [6, 2000], loss: 1.921363\n",
      "69m:55s -- [6, 4000], loss: 1.930101\n",
      "71m:21s -- [6, 6000], loss: 1.651423\n",
      "72m:43s -- [6, 8000], loss: 1.693553\n",
      "74m:9s -- [6, 10000], loss: 1.574041\n",
      "75m:34s -- [6, 12000], loss: 1.586686\n",
      "76m:59s -- [6, 14000], loss: 1.638251\n",
      "79m:33s -- [7, 2000], loss: 1.894941\n",
      "80m:53s -- [7, 4000], loss: 1.903496\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f01b80d1dfe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "all_losses = []\n",
    "\n",
    "print_every = 2000\n",
    "init_hidden_every = 35\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_cnt = 0\n",
    "    total_loss = 0.\n",
    "    \n",
    "    model.hidden = model.init_hidden()\n",
    "    \n",
    "    #dataset.shuffle_data()\n",
    "    #train_data, val_data = dataset.dataset()\n",
    "    \n",
    "    for sentence in train_data:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        loss = 0.\n",
    "        inputs = inputTensor(sentence)\n",
    "        targets = targetTensor(sentence)\n",
    "        \n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds, targets)\n",
    "            \n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        train_cnt += 1\n",
    "        \n",
    "        if train_cnt % init_hidden_every == 0:\n",
    "            model.hidden = model.init_hidden()\n",
    "        \n",
    "        if train_cnt % print_every == 0:\n",
    "            total_loss /= print_every\n",
    "            all_losses.append(total_loss)\n",
    "            uptime = time.time() - start_time\n",
    "            print('%dm:%ds -- [%d, %d], loss: %f' % (uptime/60, uptime%60, epoch, train_cnt, total_loss.data[0]))\n",
    "            total_loss = 0\n",
    "scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test(start_with, max_length):\n",
    "    model.hidden = model.init_hidden()\n",
    "    seq = str(start_with)\n",
    "    idx = []\n",
    "    \n",
    "    if len(start_with) > 1:\n",
    "        inputs = inputTensor(seq)\n",
    "        output = model(inputs)\n",
    "    \n",
    "    inputs = inputTensor(seq[-1])\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        output = model(inputs)\n",
    "        #pr = F.softmax(output.data, 1)  //pytorch 3.0+\n",
    "        pr = F.softmax(output.data)\n",
    "        pr = pr.cpu().data.numpy().squeeze()\n",
    "        pred = np.random.choice(n_letters, 1, p=pr)\n",
    "        \n",
    "        seq += all_letters[pred[0]]\n",
    "        idx.append(pred[0])\n",
    "        inputs = inputTensor(seq[-1])\n",
    "    return seq, idx\n",
    "\n",
    "def teacher_forcing_test(sentence):\n",
    "    inputs = inputTensor(sentence)\n",
    "    output = model(inputs)\n",
    "    _, preds = torch.max(output.data, 1)\n",
    "    seq = [all_letters[pred] for pred in preds ]\n",
    "    return ''.join(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence: $\n",
      "X:1\n",
      "T: Liu tote obdariel and\n",
      "R:aise\n",
      "arand tham Oem\"LON Geanlais O'Deirle \\'O. Cehssinau\n",
      "C:Th Gabas Mel\n",
      "R:aimbamminll Limammay\n",
      "A:Sre hon Sto Asten Oe\"MDyatris Rost, The Gimmia bisoiphsco? nataian\n",
      "T:Bince\n",
      "R:on bonsa-r\n",
      "R:d:hr- be-ligd\n",
      "Z:id:hansoaptoit a ewmourd Rellgc.\n",
      "C:Bokle\n",
      "Z:id:hn-par0-09\n",
      "M:1/4\n",
      "L:1/8\n",
      "K:G\n",
      "n:mabs\n",
      "cdef e3 eG cdc | A2 :|\n",
      "|: d f=fe | e2fg ddB | c2d cB | G2 G>A B>A|cBAA | B2c Ad cB|c2 d2:|\n",
      "P:Varieqlanf6 :: 1\n",
      "|: D2G F>E | G4 F2 | G3 G3 |A3 GAGG | G4 :|\n",
      "V:rriattons\n",
      "V:1\n",
      "\"D\"Ac BB|A2 G2 F2 ||\n",
      "\"D>F2 E EF | G3F FGG) |\n",
      "A2GA B2A2 | GAB deg2 | e2e2 BddB | B6f2 |\n",
      "B2A2 A2e2 | d32 (a4b2 [bothainchon: 1\n",
      "B2 B2G2 D2A | AB c2 dc | \n",
      "d2 G2 G2AG | F2A | A3 |:\n",
      "V:D\n",
      "D2 ||\n",
      "#\n",
      "$\n",
      "X:8\n",
      "T:An the Bawmhancellanear (119-08e1\n",
      "Z:id:hn-air\n",
      "M:CAnn\n",
      "Z:id:hn-d-88\n",
      "Z:id:hn-al-15\n",
      "M:CHrazrine\n",
      "S:Nigin\n",
      "Z:id:hn-air-168\n",
      "M:2/4\n",
      "L:1/8\n",
      "K:\\\n",
      "#\n",
      "$\n",
      "X:16\n",
      "T:At, T:hr-Duvpgeiumoun\n",
      "R:ar at War Barche (Th Munles Chillo!che\n",
      "T:Pyaphill\n",
      "R:Branle\n",
      "L:\n"
     ]
    }
   ],
   "source": [
    "test_seq = val_data[0]\n",
    "start_char = test_seq[:10]\n",
    "\n",
    "seq, idx = test(start_char, 900)\n",
    "print('Generated sequence: %s' % (seq))\n",
    "#print('Sequence index: ', idx)\n",
    "#print('Test sequence: %s' % test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence: 2c2 dcde | ^d3e e2fd | B2F2 G22 |: A,2D,2 | G2E3G A,3G | D4B2B2 | \n",
      "G2AB B2A3B | G2A2 c2c2|c2Ac A3G |2\n",
      "A2GBBc | c6g | e2BBAF=G3- A2F2 D2DE | EGG B4A4 | \n",
      "d3 f3e | f2f ffe/^d2 B2B2g2 | c2B2 A2 | G2B4 G6 : \"C\"f2b2 a2 | bgB bfe | ffe=c2dB | G2 A3Bde g3g |\n",
      "feBc -2me2 a2b2g2 \\\n",
      "G2F2F2|D2G2 E2D | A4:|\n",
      "#\n",
      "$\n",
      "X:88\n",
      "T:Beamfou amcher Hor STo'linat Ohmain\n",
      "R:airaai tourad\n",
      "R:a nam, iallchien\n",
      "R:a:rancen obs Beua\n",
      "M:6/8\n",
      "L:1/8\n",
      "K:G\n",
      "xt V3 E3 | GAdg \n",
      "af g2 |\n",
      "e2 a2 t3 |\n",
      "A2 G2 (3e^fu | vbiiitto:: banl Cuilags Hach\n",
      "R:fral Ponant Mattrit Thar anc.\n",
      "Z:id:hn-trie- 1\n",
      "M:2/4\n",
      "L:2/8\n",
      "Q:114=10\n",
      "K:Am\n",
      "F2E |1\n",
      "D2G) G1 GDF  D/G/G/B/ | \n",
      "c2 c2 B2 | E2 c^c A8 :|\n",
      "#\n",
      "$\n",
      "X:6\n",
      "T:Binaneuizon peqitranchy\n",
      "R:donaifr\n",
      "C:Trince\n",
      "D:Clance\n",
      "R:o pronar\n",
      "Z:id:hn-jid-6\n",
      "M:1/8\n",
      "L:1/8\n",
      "T:Palad fis\n",
      "Z:id:hn-air patous drin verl doute pal Michigai ha\n",
      "R:air\n",
      "B\n",
      "K:A\n",
      "A>BGA | AAFE E2DE | \n",
      "E  D2E2 G2E2|D2De A2FE | F2E (3G. \n",
      "[ba2a2 |bab e2fd | B2dB d3B | A4A3A G2e2 | c3B B2GF | D6EG\n"
     ]
    }
   ],
   "source": [
    "test_seq = val_data[99]\n",
    "start_char = test_seq[:10]\n",
    "\n",
    "seq, idx = test(start_char, 900)\n",
    "print('Generated sequence: %s' % (seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence: 1Z:14T:BTanpaun rn n  R:\n",
      "Test sequence: $\n",
      "X:1\n",
      "T: La Montfarine\n",
      "Z:\n"
     ]
    }
   ],
   "source": [
    "test_seq = val_data[0]\n",
    "seq = teacher_forcing_test(test_seq)\n",
    "print('Generated sequence: %s' % (seq))\n",
    "print('Test sequence: %s' % test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save_model(model, 'full-model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
