{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from rnn import RNN, PrepareData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_dim = 7\n",
    "hidden_dim = 30\n",
    "num_layers = 2\n",
    "seq_size = 25\n",
    "all_letters = string.printable\n",
    "n_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset = PrepareData('input.txt', seq_size, val_ratio=0.2)\n",
    "dataset = PrepareData('sample-music2.txt', seq_size)\n",
    "train_data, val_data = dataset.dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for idx, letter in enumerate(line[:-1]):\n",
    "        tensor[idx][0][all_letters.find(letter)] = 1\n",
    "    return Variable(tensor.cuda())\n",
    "        \n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(letter) for letter in line[1:]]\n",
    "    return Variable(torch.LongTensor(letter_indexes).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(n_letters, hidden_dim, num_layers=num_layers, output_size=n_letters)\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m:28.384814739227295 -- [0, 100], loss: 109.981651\n",
      "0m:57.71834897994995 -- [0, 200], loss: 107.848053\n",
      "1m:27.05811619758606 -- [0, 300], loss: 92.608452\n",
      "1m:56.42622637748718 -- [0, 400], loss: 85.167091\n",
      "2m:25.824209213256836 -- [0, 500], loss: 87.631920\n",
      "2m:55.2582688331604 -- [0, 600], loss: 94.421822\n",
      "3m:24.774600744247437 -- [0, 700], loss: 91.392807\n",
      "3m:53.98620676994324 -- [0, 800], loss: 85.942078\n",
      "4m:23.5032639503479 -- [0, 900], loss: 80.309448\n",
      "4m:52.73165774345398 -- [0, 1000], loss: 86.571884\n",
      "5m:22.315881967544556 -- [0, 1100], loss: 83.197678\n",
      "5m:51.640673875808716 -- [0, 1200], loss: 83.989510\n",
      "6m:21.053335428237915 -- [0, 1300], loss: 92.340523\n",
      "7m:6.79027247428894 -- [1, 100], loss: 87.203514\n",
      "7m:35.998796701431274 -- [1, 200], loss: 84.411278\n",
      "8m:6.418741703033447 -- [1, 300], loss: 77.530220\n",
      "8m:37.39429306983948 -- [1, 400], loss: 79.619461\n",
      "9m:7.832164287567139 -- [1, 500], loss: 83.479614\n",
      "9m:37.51881670951843 -- [1, 600], loss: 89.655380\n",
      "10m:7.402967214584351 -- [1, 700], loss: 87.938515\n",
      "10m:37.74191975593567 -- [1, 800], loss: 83.393364\n",
      "11m:7.458312034606934 -- [1, 900], loss: 78.340302\n",
      "11m:37.123833417892456 -- [1, 1000], loss: 84.684860\n",
      "12m:6.838292598724365 -- [1, 1100], loss: 81.771584\n",
      "12m:36.500675439834595 -- [1, 1200], loss: 83.209770\n",
      "13m:6.821190595626831 -- [1, 1300], loss: 90.972282\n",
      "13m:53.93603157997131 -- [2, 100], loss: 86.413055\n",
      "14m:23.77520227432251 -- [2, 200], loss: 84.095268\n",
      "14m:53.74232363700867 -- [2, 300], loss: 77.614555\n",
      "15m:23.138596534729004 -- [2, 400], loss: 79.417488\n",
      "15m:53.22660160064697 -- [2, 500], loss: 82.666374\n",
      "16m:23.425127506256104 -- [2, 600], loss: 87.807007\n",
      "16m:53.083035707473755 -- [2, 700], loss: 85.777901\n",
      "17m:22.837200164794922 -- [2, 800], loss: 81.419678\n",
      "17m:52.61552453041077 -- [2, 900], loss: 76.480400\n",
      "18m:22.24697756767273 -- [2, 1000], loss: 81.744049\n",
      "18m:52.08762884140015 -- [2, 1100], loss: 79.118393\n",
      "19m:24.38787865638733 -- [2, 1200], loss: 81.464668\n",
      "19m:54.69833326339722 -- [2, 1300], loss: 87.206581\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "all_losses = []\n",
    "\n",
    "print_every = 100\n",
    "init_hidden_every = 20\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_cnt = 0\n",
    "    total_loss = 0.\n",
    "    \n",
    "    model.hidden = model.init_hidden()\n",
    "    \n",
    "    #dataset.shuffle_data()\n",
    "    #train_data, val_data = dataset.dataset()\n",
    "    \n",
    "    for sentence in train_data:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        loss = 0.\n",
    "        inputs = inputTensor(sentence)\n",
    "        targets = targetTensor(sentence)\n",
    "        \n",
    "        for i in range(len(sentence)-1):\n",
    "            preds = model(inputs[i])\n",
    "            loss += criterion(preds, targets[i])\n",
    "            \n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        train_cnt += 1\n",
    "        \n",
    "        if train_cnt % init_hidden_every == 0:\n",
    "            model.hidden = model.init_hidden()\n",
    "        \n",
    "        if train_cnt % print_every == 0:\n",
    "            total_loss /= print_every\n",
    "            all_losses.append(total_loss)\n",
    "            uptime = time.time() - start_time\n",
    "            print('%dm:%s -- [%d, %d], loss: %f' % (uptime/60, uptime%60, epoch, train_cnt, total_loss))\n",
    "            total_loss = 0\n",
    "#scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      "[94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94]\n",
      "$\n",
      "X:1\n",
      "T: La Montfarine\n",
      "Z:\n"
     ]
    }
   ],
   "source": [
    "max_length = 25\n",
    "\n",
    "out_seq = []\n",
    "out_idx = []\n",
    "test_seq = train_data[0]\n",
    "inputs = inputTensor(test_seq)\n",
    "model.hidden = model.init_hidden()\n",
    "for i in range(len(test_seq)-1):\n",
    "    output = model(inputs[i])\n",
    "    _, pred = torch.max(output.data, 1)\n",
    "    out_seq.append(all_letters[int(pred)])\n",
    "    out_idx.append(pred[0])\n",
    "\n",
    "print(out_seq)\n",
    "print(out_idx)\n",
    "print(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
