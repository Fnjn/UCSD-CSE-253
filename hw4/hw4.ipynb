{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from rnn import RNN, PrepareData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_dim = 7\n",
    "hidden_dim = 30\n",
    "num_layers = 2\n",
    "seq_size = 25\n",
    "all_letters = string.printable\n",
    "n_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset = PrepareData('input.txt', seq_size, val_ratio=0.2)\n",
    "dataset = PrepareData('sample-music2.txt', seq_size)\n",
    "train_data, val_data = dataset.dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputTensor(line):\n",
    "    if len(line) == 1:\n",
    "        tensor = torch.zeros(1, n_letters)\n",
    "        tensor[0, all_letters.find(line[0])] = 1\n",
    "    else:\n",
    "        tensor = torch.zeros(len(line)-1, n_letters)\n",
    "        for idx, letter in enumerate(line[:-1]):\n",
    "            tensor[idx, all_letters.find(letter)] = 1\n",
    "    return Variable(tensor.cuda())\n",
    "        \n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(letter) for letter in line[1:]]\n",
    "    return Variable(torch.LongTensor(letter_indexes).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(n_letters, hidden_dim, num_layers=num_layers, output_size=n_letters)\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m:11.196268320083618 -- [0, 500], loss: 2.852527\n",
      "0m:25.03300905227661 -- [0, 1000], loss: 2.879465\n",
      "0m:47.27974033355713 -- [1, 500], loss: 2.827497\n",
      "1m:0.5234787464141846 -- [1, 1000], loss: 2.853377\n",
      "1m:22.691142320632935 -- [2, 500], loss: 2.803578\n",
      "1m:35.68027710914612 -- [2, 1000], loss: 2.827548\n",
      "1m:58.390618324279785 -- [3, 500], loss: 2.779727\n",
      "2m:11.446256160736084 -- [3, 1000], loss: 2.803719\n",
      "2m:33.22517538070679 -- [4, 500], loss: 2.756232\n",
      "2m:46.25396990776062 -- [4, 1000], loss: 2.780244\n",
      "3m:8.738785982131958 -- [5, 500], loss: 2.734438\n",
      "3m:21.562535524368286 -- [5, 1000], loss: 2.758514\n",
      "3m:43.81132459640503 -- [6, 500], loss: 2.713376\n",
      "3m:57.11608910560608 -- [6, 1000], loss: 2.735652\n",
      "4m:19.450064182281494 -- [7, 500], loss: 2.689895\n",
      "4m:32.194337368011475 -- [7, 1000], loss: 2.714332\n",
      "4m:54.214170932769775 -- [8, 500], loss: 2.670170\n",
      "5m:7.438884735107422 -- [8, 1000], loss: 2.694426\n",
      "5m:29.421112537384033 -- [9, 500], loss: 2.648312\n",
      "5m:42.83986020088196 -- [9, 1000], loss: 2.673491\n",
      "6m:5.38031530380249 -- [10, 500], loss: 2.626353\n",
      "6m:18.41941738128662 -- [10, 1000], loss: 2.653804\n",
      "6m:40.764259815216064 -- [11, 500], loss: 2.610484\n",
      "6m:53.65283942222595 -- [11, 1000], loss: 2.634355\n",
      "7m:15.467905759811401 -- [12, 500], loss: 2.591885\n",
      "7m:26.6679790019989 -- [12, 1000], loss: 2.618861\n",
      "7m:47.41996645927429 -- [13, 500], loss: 2.576933\n",
      "7m:59.062299728393555 -- [13, 1000], loss: 2.601856\n",
      "8m:16.245835542678833 -- [14, 500], loss: 2.559144\n",
      "8m:25.648991107940674 -- [14, 1000], loss: 2.582779\n",
      "8m:44.14414381980896 -- [15, 500], loss: 2.545586\n",
      "8m:55.599721908569336 -- [15, 1000], loss: 2.565127\n",
      "9m:13.656846761703491 -- [16, 500], loss: 2.530594\n",
      "9m:25.051902294158936 -- [16, 1000], loss: 2.551755\n",
      "9m:42.98833966255188 -- [17, 500], loss: 2.514429\n",
      "9m:52.4472815990448 -- [17, 1000], loss: 2.536584\n",
      "10m:8.692691802978516 -- [18, 500], loss: 2.499837\n",
      "10m:18.597198486328125 -- [18, 1000], loss: 2.520948\n",
      "10m:34.93134355545044 -- [19, 500], loss: 2.488035\n",
      "10m:44.68532180786133 -- [19, 1000], loss: 2.504261\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "all_losses = []\n",
    "\n",
    "print_every = 500\n",
    "init_hidden_every = 20\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_cnt = 0\n",
    "    total_loss = 0.\n",
    "    \n",
    "    model.hidden = model.init_hidden()\n",
    "    \n",
    "    #dataset.shuffle_data()\n",
    "    #train_data, val_data = dataset.dataset()\n",
    "    \n",
    "    for sentence in train_data:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        loss = 0.\n",
    "        inputs = inputTensor(sentence)\n",
    "        targets = targetTensor(sentence)\n",
    "        \n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds, targets)\n",
    "            \n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        train_cnt += 1\n",
    "        \n",
    "        if train_cnt % init_hidden_every == 0:\n",
    "            model.hidden = model.init_hidden()\n",
    "        \n",
    "        if train_cnt % print_every == 0:\n",
    "            total_loss /= print_every\n",
    "            all_losses.append(total_loss)\n",
    "            uptime = time.time() - start_time\n",
    "            print('%dm:%s -- [%d, %d], loss: %f' % (uptime/60, uptime%60, epoch, train_cnt, total_loss))\n",
    "            total_loss = 0\n",
    "#scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test(start_with, max_length):\n",
    "    model.hidden = model.init_hidden()\n",
    "    seq = str(start_with)\n",
    "    idx = []\n",
    "    inputs = inputTensor(seq[-1])\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        output = model(inputs)\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        \n",
    "        seq += all_letters[pred[0]]\n",
    "        idx.append(pred[0])\n",
    "        inputs = inputTensor(letter)\n",
    "    return seq, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence: r ccBBBcBcccBcBcccccccBcBB\n",
      "Sequence index:  [94, 12, 12, 37, 37, 37, 12, 37, 12, 12, 12, 37, 12, 37, 12, 12, 12, 12, 12, 12, 12, 37, 12, 37, 37]\n",
      "Test sequence: ree.fr\n",
      "M: 4/4\n",
      "L: 1/8\n",
      "Q:1/\n"
     ]
    }
   ],
   "source": [
    "test_seq = train_data[5]\n",
    "\n",
    "seq, idx = test(test_seq[0],25)\n",
    "print('Generated sequence: %s' % (seq))\n",
    "print('Sequence index: ', idx)\n",
    "print('Test sequence: %s' % test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
