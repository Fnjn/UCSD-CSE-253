{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from rnn import RNN, PrepareData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_dim = 7\n",
    "hidden_dim = 30\n",
    "num_layers = 2\n",
    "seq_size = 25\n",
    "all_letters = string.printable\n",
    "n_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset = PrepareData('input.txt', seq_size, val_ratio=0.2)\n",
    "dataset = PrepareData('sample-music2.txt', seq_size)\n",
    "train_data, val_data = dataset.dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputTensor(line):\n",
    "    if len(line) == 1:\n",
    "        tensor = torch.zeros(1, n_letters)\n",
    "        tensor[0, all_letters.find(line[0])] = 1\n",
    "    else:\n",
    "        tensor = torch.zeros(len(line)-1, n_letters)\n",
    "        for idx, letter in enumerate(line[:-1]):\n",
    "            tensor[idx, all_letters.find(letter)] = 1\n",
    "    return Variable(tensor.cuda())\n",
    "        \n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(letter) for letter in line[1:]]\n",
    "    return Variable(torch.LongTensor(letter_indexes).cuda())\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    \n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(n_letters, hidden_dim, num_layers=num_layers, output_size=n_letters)\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m:9.978902339935303 -- [0, 500], loss: 1.993074\n",
      "0m:20.233942985534668 -- [0, 1000], loss: 1.949602\n",
      "0m:36.09587645530701 -- [1, 500], loss: 1.986950\n",
      "0m:44.97156286239624 -- [1, 1000], loss: 1.940296\n",
      "1m:0.21548199653625488 -- [2, 500], loss: 1.983391\n",
      "1m:9.102586269378662 -- [2, 1000], loss: 1.935963\n",
      "1m:24.32178235054016 -- [3, 500], loss: 1.974745\n",
      "1m:33.17969059944153 -- [3, 1000], loss: 1.932875\n",
      "1m:48.407769203186035 -- [4, 500], loss: 1.970787\n",
      "1m:57.28315997123718 -- [4, 1000], loss: 1.922637\n",
      "2m:12.574362754821777 -- [5, 500], loss: 1.968722\n",
      "2m:21.435510635375977 -- [5, 1000], loss: 1.918855\n",
      "2m:37.609251976013184 -- [6, 500], loss: 1.961254\n",
      "2m:48.278090476989746 -- [6, 1000], loss: 1.915207\n",
      "3m:7.0418901443481445 -- [7, 500], loss: 1.956862\n",
      "3m:17.701841831207275 -- [7, 1000], loss: 1.912813\n",
      "3m:36.33969974517822 -- [8, 500], loss: 1.952200\n",
      "3m:47.2464542388916 -- [8, 1000], loss: 1.904044\n",
      "4m:5.684267997741699 -- [9, 500], loss: 1.941889\n",
      "4m:16.473621368408203 -- [9, 1000], loss: 1.898563\n",
      "4m:34.86972904205322 -- [10, 500], loss: 1.941787\n",
      "4m:45.83242130279541 -- [10, 1000], loss: 1.896843\n",
      "5m:4.506702184677124 -- [11, 500], loss: 1.934977\n",
      "5m:15.148672580718994 -- [11, 1000], loss: 1.887270\n",
      "5m:33.41144251823425 -- [12, 500], loss: 1.930241\n",
      "5m:44.269479513168335 -- [12, 1000], loss: 1.886019\n",
      "6m:3.1487843990325928 -- [13, 500], loss: 1.929247\n",
      "6m:14.047897338867188 -- [13, 1000], loss: 1.880544\n",
      "6m:32.669355154037476 -- [14, 500], loss: 1.922851\n",
      "6m:43.61976623535156 -- [14, 1000], loss: 1.876511\n",
      "7m:2.228634834289551 -- [15, 500], loss: 1.918936\n",
      "7m:12.968631982803345 -- [15, 1000], loss: 1.871557\n",
      "7m:31.69922709465027 -- [16, 500], loss: 1.911954\n",
      "7m:42.546302318573 -- [16, 1000], loss: 1.863815\n",
      "8m:0.7499921321868896 -- [17, 500], loss: 1.906102\n",
      "8m:11.448761463165283 -- [17, 1000], loss: 1.863658\n",
      "8m:30.057222843170166 -- [18, 500], loss: 1.903946\n",
      "8m:40.985841512680054 -- [18, 1000], loss: 1.856776\n",
      "8m:59.22093367576599 -- [19, 500], loss: 1.902893\n",
      "9m:10.204108238220215 -- [19, 1000], loss: 1.852584\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "all_losses = []\n",
    "\n",
    "print_every = 500\n",
    "init_hidden_every = 20\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_cnt = 0\n",
    "    total_loss = 0.\n",
    "    \n",
    "    model.hidden = model.init_hidden()\n",
    "    \n",
    "    #dataset.shuffle_data()\n",
    "    #train_data, val_data = dataset.dataset()\n",
    "    \n",
    "    for sentence in train_data:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        loss = 0.\n",
    "        inputs = inputTensor(sentence)\n",
    "        targets = targetTensor(sentence)\n",
    "        \n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds, targets)\n",
    "            \n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        train_cnt += 1\n",
    "        \n",
    "        if train_cnt % init_hidden_every == 0:\n",
    "            model.hidden = model.init_hidden()\n",
    "        \n",
    "        if train_cnt % print_every == 0:\n",
    "            total_loss /= print_every\n",
    "            all_losses.append(total_loss)\n",
    "            uptime = time.time() - start_time\n",
    "            print('%dm:%s -- [%d, %d], loss: %f' % (uptime/60, uptime%60, epoch, train_cnt, total_loss))\n",
    "            total_loss = 0\n",
    "#scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test(start_with, max_length):\n",
    "    model.hidden = model.init_hidden()\n",
    "    seq = str(start_with)\n",
    "    idx = []\n",
    "    inputs = inputTensor(seq[-1])\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        output = model(inputs)\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        \n",
    "        seq += all_letters[pred[0]]\n",
    "        idx.append(pred[0])\n",
    "        inputs = inputTensor(letter)\n",
    "    return seq, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence: M BBBBB|Bccccccccccccccccc\n",
      "Sequence index:  [94, 37, 37, 37, 37, 37, 91, 37, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "Test sequence: ree.fr\n",
      "M: 4/4\n",
      "L: 1/8\n",
      "Q:1/\n"
     ]
    }
   ],
   "source": [
    "test_seq = train_data[5]\n",
    "\n",
    "seq, idx = test(test_seq[7],25)\n",
    "print('Generated sequence: %s' % (seq))\n",
    "print('Sequence index: ', idx)\n",
    "print('Test sequence: %s' % test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(model, 'sample-model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
